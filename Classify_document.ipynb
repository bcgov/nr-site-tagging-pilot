{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14b77e80-51cc-4da4-b1eb-07327ba4578e",
   "metadata": {},
   "source": [
    "## Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8762c09-650b-44d5-b9e4-4723a023b8e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openpyxl in /Users/deepaksirwani/miniforge3/envs/colx563/lib/python3.10/site-packages (3.1.5)\n",
      "Requirement already satisfied: et-xmlfile in /Users/deepaksirwani/miniforge3/envs/colx563/lib/python3.10/site-packages (from openpyxl) (2.0.0)\n",
      "Requirement already satisfied: datasets in /Users/deepaksirwani/miniforge3/envs/colx563/lib/python3.10/site-packages (3.5.1)\n",
      "Requirement already satisfied: filelock in /Users/deepaksirwani/miniforge3/envs/colx563/lib/python3.10/site-packages (from datasets) (3.17.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/deepaksirwani/miniforge3/envs/colx563/lib/python3.10/site-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /Users/deepaksirwani/miniforge3/envs/colx563/lib/python3.10/site-packages (from datasets) (19.0.1)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /Users/deepaksirwani/miniforge3/envs/colx563/lib/python3.10/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /Users/deepaksirwani/miniforge3/envs/colx563/lib/python3.10/site-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in /Users/deepaksirwani/miniforge3/envs/colx563/lib/python3.10/site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /Users/deepaksirwani/miniforge3/envs/colx563/lib/python3.10/site-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /Users/deepaksirwani/miniforge3/envs/colx563/lib/python3.10/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /Users/deepaksirwani/miniforge3/envs/colx563/lib/python3.10/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /Users/deepaksirwani/miniforge3/envs/colx563/lib/python3.10/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.2.0)\n",
      "Requirement already satisfied: aiohttp in /Users/deepaksirwani/miniforge3/envs/colx563/lib/python3.10/site-packages (from datasets) (3.11.16)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in /Users/deepaksirwani/miniforge3/envs/colx563/lib/python3.10/site-packages (from datasets) (0.30.1)\n",
      "Requirement already satisfied: packaging in /Users/deepaksirwani/miniforge3/envs/colx563/lib/python3.10/site-packages (from datasets) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/deepaksirwani/miniforge3/envs/colx563/lib/python3.10/site-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /Users/deepaksirwani/miniforge3/envs/colx563/lib/python3.10/site-packages (from aiohttp->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/deepaksirwani/miniforge3/envs/colx563/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /Users/deepaksirwani/miniforge3/envs/colx563/lib/python3.10/site-packages (from aiohttp->datasets) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/deepaksirwani/miniforge3/envs/colx563/lib/python3.10/site-packages (from aiohttp->datasets) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/deepaksirwani/miniforge3/envs/colx563/lib/python3.10/site-packages (from aiohttp->datasets) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/deepaksirwani/miniforge3/envs/colx563/lib/python3.10/site-packages (from aiohttp->datasets) (6.4.2)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Users/deepaksirwani/miniforge3/envs/colx563/lib/python3.10/site-packages (from aiohttp->datasets) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Users/deepaksirwani/miniforge3/envs/colx563/lib/python3.10/site-packages (from aiohttp->datasets) (1.19.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/deepaksirwani/miniforge3/envs/colx563/lib/python3.10/site-packages (from huggingface-hub>=0.24.0->datasets) (4.12.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/deepaksirwani/miniforge3/envs/colx563/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/deepaksirwani/miniforge3/envs/colx563/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/deepaksirwani/miniforge3/envs/colx563/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/deepaksirwani/miniforge3/envs/colx563/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/deepaksirwani/miniforge3/envs/colx563/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/deepaksirwani/miniforge3/envs/colx563/lib/python3.10/site-packages (from pandas->datasets) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/deepaksirwani/miniforge3/envs/colx563/lib/python3.10/site-packages (from pandas->datasets) (2025.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/deepaksirwani/miniforge3/envs/colx563/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Requirement already satisfied: transformers[torch] in /Users/deepaksirwani/miniforge3/envs/colx563/lib/python3.10/site-packages (4.50.3)\n",
      "Requirement already satisfied: filelock in /Users/deepaksirwani/miniforge3/envs/colx563/lib/python3.10/site-packages (from transformers[torch]) (3.17.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in /Users/deepaksirwani/miniforge3/envs/colx563/lib/python3.10/site-packages (from transformers[torch]) (0.30.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/deepaksirwani/miniforge3/envs/colx563/lib/python3.10/site-packages (from transformers[torch]) (2.2.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/deepaksirwani/miniforge3/envs/colx563/lib/python3.10/site-packages (from transformers[torch]) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/deepaksirwani/miniforge3/envs/colx563/lib/python3.10/site-packages (from transformers[torch]) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/deepaksirwani/miniforge3/envs/colx563/lib/python3.10/site-packages (from transformers[torch]) (2024.11.6)\n",
      "Requirement already satisfied: requests in /Users/deepaksirwani/miniforge3/envs/colx563/lib/python3.10/site-packages (from transformers[torch]) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /Users/deepaksirwani/miniforge3/envs/colx563/lib/python3.10/site-packages (from transformers[torch]) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /Users/deepaksirwani/miniforge3/envs/colx563/lib/python3.10/site-packages (from transformers[torch]) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/deepaksirwani/miniforge3/envs/colx563/lib/python3.10/site-packages (from transformers[torch]) (4.67.1)\n",
      "Requirement already satisfied: torch>=2.0 in /Users/deepaksirwani/miniforge3/envs/colx563/lib/python3.10/site-packages (from transformers[torch]) (2.5.1)\n",
      "Requirement already satisfied: accelerate>=0.26.0 in /Users/deepaksirwani/miniforge3/envs/colx563/lib/python3.10/site-packages (from transformers[torch]) (1.6.0)\n",
      "Requirement already satisfied: psutil in /Users/deepaksirwani/miniforge3/envs/colx563/lib/python3.10/site-packages (from accelerate>=0.26.0->transformers[torch]) (6.1.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/deepaksirwani/miniforge3/envs/colx563/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.26.0->transformers[torch]) (2025.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/deepaksirwani/miniforge3/envs/colx563/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.26.0->transformers[torch]) (4.12.2)\n",
      "Requirement already satisfied: networkx in /Users/deepaksirwani/miniforge3/envs/colx563/lib/python3.10/site-packages (from torch>=2.0->transformers[torch]) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /Users/deepaksirwani/miniforge3/envs/colx563/lib/python3.10/site-packages (from torch>=2.0->transformers[torch]) (3.1.5)\n",
      "Requirement already satisfied: sympy==1.13.1 in /Users/deepaksirwani/miniforge3/envs/colx563/lib/python3.10/site-packages (from torch>=2.0->transformers[torch]) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/deepaksirwani/miniforge3/envs/colx563/lib/python3.10/site-packages (from sympy==1.13.1->torch>=2.0->transformers[torch]) (1.3.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/deepaksirwani/miniforge3/envs/colx563/lib/python3.10/site-packages (from requests->transformers[torch]) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/deepaksirwani/miniforge3/envs/colx563/lib/python3.10/site-packages (from requests->transformers[torch]) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/deepaksirwani/miniforge3/envs/colx563/lib/python3.10/site-packages (from requests->transformers[torch]) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/deepaksirwani/miniforge3/envs/colx563/lib/python3.10/site-packages (from requests->transformers[torch]) (2025.1.31)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/deepaksirwani/miniforge3/envs/colx563/lib/python3.10/site-packages (from jinja2->torch>=2.0->transformers[torch]) (3.0.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install openpyxl\n",
    "!pip install datasets\n",
    "!pip install \"transformers[torch]\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0167f2f7-caa0-4d58-8fd9-33e6e3aee0c0",
   "metadata": {},
   "source": [
    "## Load Excel file containing labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9c1cd916-61a2-45d8-8609-f988051ebbee",
   "metadata": {},
   "outputs": [],
   "source": [
    "excel_path = '../data/2025-05-01 Capstone Metadata.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dbdd4cb6-5f94-4e3e-99b6-dd688ffe3071",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Document Type</th>\n",
       "      <th>Title/Subject</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CORR</td>\n",
       "      <td>Standards, Analytical Results</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>COV</td>\n",
       "      <td>Covenant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CORR</td>\n",
       "      <td>Certificate of Compliance, Pursuant to Section...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CoC</td>\n",
       "      <td>Conditional Certificate of Compliance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CoC</td>\n",
       "      <td>Conditional Certificate of Compliance</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Document Type                                      Title/Subject\n",
       "0          CORR                      Standards, Analytical Results\n",
       "1           COV                                           Covenant\n",
       "2          CORR  Certificate of Compliance, Pursuant to Section...\n",
       "3           CoC              Conditional Certificate of Compliance\n",
       "4           CoC              Conditional Certificate of Compliance"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel(excel_path, header=3)\n",
    "df = df[['Document Type', 'Title/Subject']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "46c51a1a-9a1e-4edf-8340-af7423ba2ed8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document Type\n",
       "CORR             103\n",
       "RPT               19\n",
       "TMEMO             17\n",
       "PSI               12\n",
       "TITLE             10\n",
       "MAP                7\n",
       "COC                6\n",
       "Site Registry      6\n",
       "FDET               5\n",
       "DSI                5\n",
       "RA                 5\n",
       "CSSA               5\n",
       "NOTE               4\n",
       "CoC                4\n",
       "PDET               3\n",
       "REF                2\n",
       "NIRI               2\n",
       "SSI                2\n",
       "AIP                2\n",
       "COV                1\n",
       "IMG                1\n",
       "SP                 1\n",
       "COA                1\n",
       "AiP                1\n",
       "SPC                1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Document Type'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da01cade-70ce-4898-9cab-84532bed44e1",
   "metadata": {},
   "source": [
    "## Some names were not consistent. Make them consistent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a4af675-359b-4279-92b0-c9a9ed3cc4b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "rename_map = {\n",
    "    'CoC' : 'COC',\n",
    "    'AiP' : 'AIP',\n",
    "    'NOTE': 'OTHERS',\n",
    "    'REF': 'OTHERS',\n",
    "    'SPC': 'OTHERS'\n",
    "}\n",
    "\n",
    "df['Document Type'] = df['Document Type'].replace(rename_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6cffc637-d66b-468c-8be5-4ad8b30aed66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Document Type</th>\n",
       "      <th>Title/Subject</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CORR</td>\n",
       "      <td>Standards, Analytical Results</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>COV</td>\n",
       "      <td>Covenant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CORR</td>\n",
       "      <td>Certificate of Compliance, Pursuant to Section...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>COC</td>\n",
       "      <td>Conditional Certificate of Compliance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>COC</td>\n",
       "      <td>Conditional Certificate of Compliance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>RPT</td>\n",
       "      <td>Site Remediation Report\\nNorth Kamloops Fire H...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>RPT</td>\n",
       "      <td>Underground Storage Tank Decommissioning,\\nSup...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>RPT</td>\n",
       "      <td>Geotechnical Investigation\\nProposed Senior Ci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>PSI</td>\n",
       "      <td>STAGE 2 PSI\\nCITY OF KAMLOOPS FIREHALL NO. 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>PSI</td>\n",
       "      <td>STAGE 1\\nPRELIMINARY SITE INVESTIGATION\\nCITY ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>225 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Document Type                                      Title/Subject\n",
       "0            CORR                      Standards, Analytical Results\n",
       "1             COV                                           Covenant\n",
       "2            CORR  Certificate of Compliance, Pursuant to Section...\n",
       "3             COC              Conditional Certificate of Compliance\n",
       "4             COC              Conditional Certificate of Compliance\n",
       "..            ...                                                ...\n",
       "220           RPT  Site Remediation Report\\nNorth Kamloops Fire H...\n",
       "221           RPT  Underground Storage Tank Decommissioning,\\nSup...\n",
       "222           RPT  Geotechnical Investigation\\nProposed Senior Ci...\n",
       "223           PSI       STAGE 2 PSI\\nCITY OF KAMLOOPS FIREHALL NO. 2\n",
       "224           PSI  STAGE 1\\nPRELIMINARY SITE INVESTIGATION\\nCITY ...\n",
       "\n",
       "[225 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "90b40ebd-1b29-4047-9a73-ab3dc4894abd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document Type\n",
       "CORR             103\n",
       "RPT               19\n",
       "TMEMO             17\n",
       "PSI               12\n",
       "COC               10\n",
       "TITLE             10\n",
       "OTHERS             7\n",
       "MAP                7\n",
       "Site Registry      6\n",
       "CSSA               5\n",
       "FDET               5\n",
       "RA                 5\n",
       "DSI                5\n",
       "PDET               3\n",
       "AIP                3\n",
       "NIRI               2\n",
       "SSI                2\n",
       "SP                 1\n",
       "COV                1\n",
       "IMG                1\n",
       "COA                1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Document Type'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b28a2b-26ff-4afb-a596-5928bbc8dd80",
   "metadata": {},
   "source": [
    "## Data Augmentation to make sure minority classes are not underrepresented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3a1a534f-1120-4534-bbdb-c05f29fe2ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_row = pd.DataFrame([\n",
    "        {'Document Type': 'COV', \n",
    "        'Title/Subject': '''Covenant'''},\n",
    "            {'Document Type': 'COA', \n",
    "        'Title/Subject': '''Certifi cate of Analysis for document of Site 3452'''},\n",
    "        {'Document Type': 'COA', \n",
    "        'Title/Subject': '''Certificate of Analysis Document no 3425'''},\n",
    "    {'Document Type': 'COA', \n",
    "        'Title/Subject': '''Certificate of\\n\\n Analysis done completely'''},\n",
    "        {'Document Type': 'COA', \n",
    "        'Title/Subject': '''Certificate of completed Analysis'''},\n",
    "            {'Document Type': 'IMG', \n",
    "        'Title/Subject': '''Pictures'''},\n",
    "    {'Document Type': 'IMG', \n",
    "        'Title/Subject': '''Images'''},\n",
    "    {'Document Type': 'IMG', \n",
    "        'Title/Subject': '''JPEGS'''},\n",
    "    {'Document Type': 'IMG', \n",
    "        'Title/Subject': '''PNGS'''},\n",
    "    {'Document Type': 'COV', \n",
    "        'Title/Subject': '''Cov\\enant'''},\n",
    "    {'Document Type': 'COV', \n",
    "        'Title/Subject': '''Covenant Report'''},\n",
    "    {'Document Type': 'COV', \n",
    "        'Title/Subject': '''Covenant Based on '''},\n",
    "    {'Document Type': 'SP', \n",
    "        'Title/Subject': '''Schedule 2 Site Profile'''},\n",
    "        {'Document Type': 'SP', \n",
    "        'Title/Subject': '''Schedule 3 Site Profile'''},\n",
    "      {'Document Type': 'SP', \n",
    "        'Title/Subject': '''Schedule 4 Site Profile'''},\n",
    "    {'Document Type': 'SP', \n",
    "        'Title/Subject': '''Schedule 5 Site Profile'''},\n",
    "    {'Document Type': 'PDET', \n",
    "        'Title/Subject': '''preliminary\\ndetermination for Site 2345'''},\n",
    "    {'Document Type': 'SSI', \n",
    "        'Title/Subject': '''STAGE 1 AND 2 PSI, DSI AND CLOSURE REP\\nORTING\\n'''},\n",
    "    {'Document Type': 'SSI', \n",
    "        'Title/Subject': '''STAGE 1 AND 2 PSI, DSI AND CLOSURE REPORTING ADDITIONAL SUPPLEMENTAL INFORMATION (given on page 32)'''},\n",
    "    {'Document Type': 'SSI', \n",
    "        'Title/Subject': '''STAGE 1 AND 2 PSI, DSI AND CLOSURE REPORTING SUPPLEMENTAL INFORMATION OR ADDITIONAL\\n'''},\n",
    "    {'Document Type': 'AIP', \n",
    "        'Title/Subject': '''APPROVAL In Principle, technical report for PA 16456'''},\n",
    "    {'Document Type': 'AIP', \n",
    "        'Title/Subject': '''Approval in Principle, AIP 23663'''},\n",
    "    {'Document Type': 'PDET', \n",
    "        'Title/Subject': '''Preliminary Determination for Section 26.4  for the property\\nlocated at 736 Main Street'''},\n",
    "    {'Document Type': 'NIRI', \n",
    "    'Title/Subject': '''Notice of Independent Remediation  \n",
    "    Vancouver, British Columbia'''}, \n",
    "    {'Document Type': 'NIRI', \n",
    "        'Title/Subject': '''Notice of Independent Remediation'''},\n",
    "        {'Document Type': 'NIRI', \n",
    "    'Title/Subject': '''RE: NOTICE OF INDEP ENDENT REMEDIA\\nTION\\tMOBILE PHONE NO. 72 STREET, SHAMBALA, BC\\n'''}])\n",
    "df = pd.concat([df, new_row], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6914120d-8621-4002-b270-7cb57c0ce680",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document Type\n",
       "CORR             103\n",
       "RPT               19\n",
       "TMEMO             17\n",
       "PSI               12\n",
       "COC               10\n",
       "TITLE             10\n",
       "OTHERS             7\n",
       "MAP                7\n",
       "Site Registry      6\n",
       "SP                 5\n",
       "CSSA               5\n",
       "COV                5\n",
       "PDET               5\n",
       "IMG                5\n",
       "FDET               5\n",
       "RA                 5\n",
       "DSI                5\n",
       "COA                5\n",
       "NIRI               5\n",
       "AIP                5\n",
       "SSI                5\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Document Type'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a80494eb-319f-47b5-9e36-552c4800bb99",
   "metadata": {},
   "source": [
    "## Train, test, val splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "46c9969b-1625-4e23-9f2e-a2b676a71aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from math import ceil\n",
    "\n",
    "# Shuffle the dataset\n",
    "df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Containers for splits\n",
    "train_rows, val_rows, test_rows = [], [], []\n",
    "\n",
    "# Per-class splitting\n",
    "for label, group in df.groupby('Document Type'):\n",
    "    n = len(group)\n",
    "    n_train = int(n * 0.6)\n",
    "    n_val = int(n * 0.2)\n",
    "    n_test = n - n_train - n_val  # ensures all rows are used\n",
    "\n",
    "    train_rows.append(group.iloc[:n_train])\n",
    "    val_rows.append(group.iloc[n_train:n_train + n_val])\n",
    "    test_rows.append(group.iloc[n_train + n_val:])\n",
    "\n",
    "# Concatenate all rows\n",
    "train_df = pd.concat(train_rows).reset_index(drop=True)\n",
    "val_df = pd.concat(val_rows).reset_index(drop=True)\n",
    "test_df = pd.concat(test_rows).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a47b6b8b-303d-4dbc-ab14-e4865eb80a89",
   "metadata": {},
   "source": [
    "## Prepare data for training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1826189e-e44c-400a-ba77-cdf009467ec6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/deepaksirwani/miniforge3/envs/colx563/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "train_df = train_df.rename(columns={'Title/Subject': 'text'})\n",
    "train_df['text'] = train_df['text'].astype(str).fillna('')\n",
    "\n",
    "val_df = val_df.rename(columns={'Title/Subject': 'text'})\n",
    "test_df = test_df.rename(columns={'Title/Subject': 'text'})\n",
    "\n",
    "# Label encode target\n",
    "le = LabelEncoder()\n",
    "train_df['label'] = le.fit_transform(train_df['Document Type'])\n",
    "val_df['label'] = le.transform(val_df['Document Type'])\n",
    "test_df['label'] = le.transform(test_df['Document Type'])\n",
    "\n",
    "# Create Hugging Face Datasets\n",
    "train_ds = Dataset.from_pandas(train_df[['text', 'label']])\n",
    "val_ds = Dataset.from_pandas(val_df[['text', 'label']])\n",
    "test_ds = Dataset.from_pandas(test_df[['text', 'label']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a8cb93ce-dead-4046-8b70-c62a950c33e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|█████████████████████████████| 47/47 [00:00<00:00, 2979.94 examples/s]\n",
      "Map: 100%|████████████████████████████| 56/56 [00:00<00:00, 11336.50 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "def tokenize(batch):\n",
    "    texts = list(batch['text'])  # force list in case it's not\n",
    "    return tokenizer(\n",
    "        texts,\n",
    "        truncation=True,\n",
    "        padding='max_length',\n",
    "        max_length=64\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "train_ds = train_ds.map(tokenize, batched=True)\n",
    "val_ds = val_ds.map(tokenize, batched=True)\n",
    "test_ds = test_ds.map(tokenize, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81338db5-15b6-4ad5-af63-169180f59c0a",
   "metadata": {},
   "source": [
    "## Load Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cbe1a2a7-3313-493f-b371-014cd7eb630f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/deepaksirwani/miniforge3/envs/colx563/lib/python3.10/site-packages/torchvision/io/image.py:14: UserWarning: Failed to load image Python extension: 'dlopen(/Users/deepaksirwani/miniforge3/envs/colx563/lib/python3.10/site-packages/torchvision/image.so, 0x0006): Library not loaded: @rpath/libjpeg.9.dylib\n",
      "  Referenced from: <0B7EB158-53DC-3403-8A49-22178CAB4612> /Users/deepaksirwani/miniforge3/envs/colx563/lib/python3.10/site-packages/torchvision/image.so\n",
      "  Reason: tried: '/Users/deepaksirwani/miniforge3/envs/colx563/lib/python3.10/site-packages/torchvision/../../../libjpeg.9.dylib' (no such file), '/Users/deepaksirwani/miniforge3/envs/colx563/lib/python3.10/site-packages/torchvision/../../../libjpeg.9.dylib' (no such file), '/Users/deepaksirwani/miniforge3/envs/colx563/lib/python3.10/lib-dynload/../../libjpeg.9.dylib' (no such file), '/Users/deepaksirwani/miniforge3/envs/colx563/bin/../lib/libjpeg.9.dylib' (no such file)'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DistilBertForSequenceClassification(\n",
       "  (distilbert): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0-5): 6 x TransformerBlock(\n",
       "          (attention): DistilBertSdpaAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (classifier): Linear(in_features=768, out_features=21, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "os.environ[\"PYTORCH_ENABLE_MPS_FALLBACK\"] = \"1\"\n",
    "\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(train_df['label']),\n",
    "    y=train_df['label']\n",
    ")\n",
    "\n",
    "# Convert to torch tensor\n",
    "class_weights = torch.tensor(class_weights, dtype=torch.float)\n",
    "class_weights = class_weights.to(device)\n",
    "\n",
    "\n",
    "num_labels = len(le.classes_)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    'distilbert-base-uncased',\n",
    "    num_labels=num_labels\n",
    ")\n",
    "model.to(device)\n",
    "\n",
    "# model.classifier.weight = torch.nn.Parameter(model.classifier.weight * class_weights.unsqueeze(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f6d6602c-7027-40ec-8796-36b4c5718419",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds.set_format('torch', columns=['input_ids', 'attention_mask', 'label'])\n",
    "val_ds.set_format('torch', columns=['input_ids', 'attention_mask', 'label'])\n",
    "test_ds.set_format('torch', columns=['input_ids', 'attention_mask', 'label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d494312-1628-4a2a-8f2a-4b9b810ecc9e",
   "metadata": {},
   "source": [
    "## Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c9143581-3c6d-444e-85b8-880ebd8035ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss(weight=class_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88315621-da3e-42e4-b5bb-01dba5cd9b37",
   "metadata": {},
   "source": [
    "## Train the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "efde3322-ebda-40e9-a25d-fd5d140b4645",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/deepaksirwani/miniforge3/envs/colx563/lib/python3.10/site-packages/transformers/training_args.py:1611: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/var/folders/xx/mk_s8q213n37jfd4755v6dfr0000gn/T/ipykernel_21671/3167783769.py:70: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `WeightedCETrainer.__init__`. Use `processing_class` instead.\n",
      "  super().__init__(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='500' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [500/500 03:03, Epoch 50/50]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.041000</td>\n",
       "      <td>3.017980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.976900</td>\n",
       "      <td>2.955700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.891300</td>\n",
       "      <td>2.876013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.749600</td>\n",
       "      <td>2.789028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2.668600</td>\n",
       "      <td>2.688093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>2.480600</td>\n",
       "      <td>2.582090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>2.348400</td>\n",
       "      <td>2.468308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>2.164600</td>\n",
       "      <td>2.366463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>2.057800</td>\n",
       "      <td>2.268936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.944900</td>\n",
       "      <td>2.165347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>1.785900</td>\n",
       "      <td>2.062803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>1.702900</td>\n",
       "      <td>1.984008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>1.666200</td>\n",
       "      <td>1.898778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>1.481600</td>\n",
       "      <td>1.848926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>1.411700</td>\n",
       "      <td>1.776511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>1.308100</td>\n",
       "      <td>1.703025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>1.258100</td>\n",
       "      <td>1.658318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>1.169400</td>\n",
       "      <td>1.612389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>1.061600</td>\n",
       "      <td>1.566279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.034400</td>\n",
       "      <td>1.515596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.986600</td>\n",
       "      <td>1.475701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.914100</td>\n",
       "      <td>1.458842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.865600</td>\n",
       "      <td>1.424752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.808100</td>\n",
       "      <td>1.401546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.794500</td>\n",
       "      <td>1.374634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.797800</td>\n",
       "      <td>1.359371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.690400</td>\n",
       "      <td>1.347090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.679700</td>\n",
       "      <td>1.331558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.619600</td>\n",
       "      <td>1.318005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.604900</td>\n",
       "      <td>1.289661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>0.661600</td>\n",
       "      <td>1.269822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.533400</td>\n",
       "      <td>1.284585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>0.509600</td>\n",
       "      <td>1.259559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>0.492200</td>\n",
       "      <td>1.240759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.463400</td>\n",
       "      <td>1.231258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>0.438700</td>\n",
       "      <td>1.237164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>0.449200</td>\n",
       "      <td>1.225672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>0.422800</td>\n",
       "      <td>1.234368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>0.407300</td>\n",
       "      <td>1.225011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.395500</td>\n",
       "      <td>1.216757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>0.382600</td>\n",
       "      <td>1.218987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>0.368400</td>\n",
       "      <td>1.222761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>0.388100</td>\n",
       "      <td>1.215465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>0.355000</td>\n",
       "      <td>1.212944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>0.397900</td>\n",
       "      <td>1.215417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>0.363500</td>\n",
       "      <td>1.214175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>0.348700</td>\n",
       "      <td>1.210316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>0.366200</td>\n",
       "      <td>1.207855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>0.354300</td>\n",
       "      <td>1.207534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.342200</td>\n",
       "      <td>1.207284</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=500, training_loss=1.1081169352531433, metrics={'train_runtime': 184.1717, 'train_samples_per_second': 40.18, 'train_steps_per_second': 2.715, 'total_flos': 122573862374400.0, 'train_loss': 1.1081169352531433, 'epoch': 50.0})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "# training_args = TrainingArguments(\n",
    "#     output_dir='./results',\n",
    "#     evaluation_strategy='epoch',\n",
    "#     save_strategy='epoch',\n",
    "#     load_best_model_at_end=True,\n",
    "#     learning_rate=2e-5,\n",
    "#     per_device_train_batch_size=16,\n",
    "#     per_device_eval_batch_size=32,\n",
    "#     num_train_epochs=50,\n",
    "#     weight_decay=0.01,\n",
    "#     logging_dir='./logs',\n",
    "#     logging_steps=10,\n",
    "#     no_cuda=True\n",
    "# )\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",              \n",
    "    load_best_model_at_end=True,        \n",
    "    save_total_limit=1,                 \n",
    "    save_steps=0,                       \n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=32,\n",
    "    num_train_epochs=50,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=10,\n",
    "    learning_rate=2e-5,\n",
    ")\n",
    "\n",
    "# from transformers import Trainer\n",
    "\n",
    "# trainer = Trainer(\n",
    "#     model=model,\n",
    "#     args=training_args,\n",
    "#     train_dataset=train_ds,\n",
    "#     eval_dataset=val_ds,\n",
    "#     tokenizer=tokenizer,\n",
    "# )\n",
    "# trainer.train()\n",
    "\n",
    "\n",
    "from transformers import Trainer\n",
    "\n",
    "# class FocalLossTrainer(Trainer):\n",
    "#     def __init__(self, focal_loss_fn, *args, **kwargs):\n",
    "#         super().__init__(*args, **kwargs)\n",
    "#         self.focal_loss_fn = focal_loss_fn\n",
    "\n",
    "#     def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n",
    "#         labels = inputs.pop(\"labels\")\n",
    "    \n",
    "#         # Force CPU\n",
    "#         device = torch.device(\"cpu\")\n",
    "#         labels = labels.to(device)\n",
    "#         model.to(device)\n",
    "#         for k in inputs:\n",
    "#             if isinstance(inputs[k], torch.Tensor):\n",
    "#                 inputs[k] = inputs[k].to(device)\n",
    "\n",
    "#         outputs = model(**inputs)\n",
    "#         logits = outputs.logits\n",
    "#         loss = self.focal_loss_fn(logits, labels)\n",
    "#         return (loss, outputs) if return_outputs else loss\n",
    "\n",
    "class WeightedCETrainer(Trainer):\n",
    "    def __init__(self, loss_fn, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.loss_fn = loss_fn\n",
    "\n",
    "    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n",
    "        labels = inputs.pop(\"labels\")\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        labels = labels.to(logits.device)\n",
    "        self.loss_fn.weight = self.loss_fn.weight.to(logits.device)\n",
    "        loss = self.loss_fn(logits, labels)\n",
    "        return (loss, outputs) if return_outputs else loss\n",
    "\n",
    "\n",
    "\n",
    "# focal_loss = WeightedFocalLoss(alpha=class_weights, gamma=1.0)\n",
    "\n",
    "# trainer = FocalLossTrainer(\n",
    "#     model=model,\n",
    "#     args=training_args,\n",
    "#     train_dataset=train_ds,\n",
    "#     eval_dataset=val_ds,\n",
    "#     tokenizer=tokenizer,\n",
    "#     focal_loss_fn=focal_loss\n",
    "# )\n",
    "\n",
    "trainer = WeightedCETrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=val_ds,\n",
    "    tokenizer=tokenizer,\n",
    "    loss_fn=loss_fn\n",
    ")\n",
    "\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc6d6324-0405-4587-a7a9-2ee0aede29df",
   "metadata": {},
   "source": [
    "## Get performance on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d02ae3de-0ef7-4842-9212-bcd031c12af4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "          AIP       1.00      1.00      1.00         1\n",
      "          COA       1.00      1.00      1.00         1\n",
      "          COC       1.00      1.00      1.00         2\n",
      "         CORR       0.74      0.91      0.82        22\n",
      "          COV       1.00      1.00      1.00         1\n",
      "         CSSA       0.00      0.00      0.00         1\n",
      "          DSI       1.00      1.00      1.00         1\n",
      "         FDET       1.00      1.00      1.00         1\n",
      "          IMG       1.00      1.00      1.00         1\n",
      "          MAP       0.50      0.50      0.50         2\n",
      "         NIRI       1.00      1.00      1.00         1\n",
      "       OTHERS       0.00      0.00      0.00         2\n",
      "         PDET       1.00      1.00      1.00         1\n",
      "          PSI       1.00      1.00      1.00         3\n",
      "           RA       0.50      1.00      0.67         1\n",
      "          RPT       1.00      0.80      0.89         5\n",
      "           SP       1.00      1.00      1.00         1\n",
      "          SSI       1.00      1.00      1.00         1\n",
      "Site Registry       1.00      1.00      1.00         2\n",
      "        TITLE       1.00      1.00      1.00         2\n",
      "        TMEMO       0.00      0.00      0.00         4\n",
      "\n",
      "     accuracy                           0.80        56\n",
      "    macro avg       0.80      0.82      0.80        56\n",
      " weighted avg       0.75      0.80      0.77        56\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/deepaksirwani/miniforge3/envs/colx563/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/deepaksirwani/miniforge3/envs/colx563/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/deepaksirwani/miniforge3/envs/colx563/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "preds = trainer.predict(test_ds)\n",
    "pred_labels = preds.predictions.argmax(axis=-1)\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(test_ds['label'], pred_labels, target_names=le.classes_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "733f7dc8-035b-4d3d-a9bf-08025bf35c3d",
   "metadata": {},
   "source": [
    "## Save the best model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6a0e41dd-e5b1-44cb-ac5c-6de4e7b9976d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./best_model/tokenizer_config.json',\n",
       " './best_model/special_tokens_map.json',\n",
       " './best_model/vocab.txt',\n",
       " './best_model/added_tokens.json',\n",
       " './best_model/tokenizer.json')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.save_model(\"./best_model\")               # saves model weights + config\n",
    "tokenizer.save_pretrained(\"./best_model\")        # saves tokenizer (needed for inference)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb145fe9-8a23-497d-b09c-50198f37c816",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3058d304-adb6-4100-b7fd-a1efe39aced7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Certificate of Compliance for Section 28 → COC\n",
      "Preliminary Site Investigation for North Shore → PSI\n",
      "Images of Soil Contamination → IMG\n",
      "Analytical Lab Results → CORR\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "\n",
    "# Load tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained('./best_model')\n",
    "model = AutoModelForSequenceClassification.from_pretrained('./best_model')\n",
    "model.eval()\n",
    "\n",
    "# Replace with your actual class names\n",
    "class_names = [\n",
    "    'AIP', 'COA', 'COC', 'CORR', 'COV', 'CSSA', 'DSI', 'FDET', 'IMG', 'MAP',\n",
    "    'NIRI', 'OTHERS', 'PDET', 'PSI', 'RA', 'RPT', 'SP', 'SSI', 'Site Registry',\n",
    "    'TITLE', 'TMEMO'\n",
    "]\n",
    "\n",
    "# Prediction function\n",
    "def predict_document_type(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=\"max_length\", max_length=64)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    logits = outputs.logits\n",
    "    predicted_class_id = logits.argmax().item()\n",
    "    return class_names[predicted_class_id]\n",
    "\n",
    "# Example usage\n",
    "example_titles = [\n",
    "    \"Certificate of Compliance for Section 28\",\n",
    "    \"Preliminary Site Investigation for North Shore\",\n",
    "    \"Images of Soil Contamination\",\n",
    "    \"Analytical Lab Results\"\n",
    "    \n",
    "]\n",
    "\n",
    "predictions = [predict_document_type(title) for title in example_titles]\n",
    "for title, label in zip(example_titles, predictions):\n",
    "    print(f\"{title} → {label}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:colx563]",
   "language": "python",
   "name": "conda-env-colx563-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
